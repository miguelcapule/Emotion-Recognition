{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4267663",
   "metadata": {},
   "outputs": [],
   "source": [
    " import tensorflow as tf ##pip install tensorflow\n",
    "    import cv2 ##pip install opencv-python\n",
    "    import os\n",
    "    import matplotlib.pyplot as plt ##pip install matplotlib\n",
    "    import numpy as np ##pip install numpy\n",
    "\n",
    "\n",
    "    # Path to the Haar Cascade classifier XML file\n",
    "    path = \"haarcascade_frontalface_default.xml\"\n",
    "\n",
    "    # Font settings for displaying emotion labels\n",
    "    font_scale = 1.5\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "    # Initialize a white background image with text\n",
    "    rectangle_bgr = (255, 255, 255)\n",
    "    img = np.zeros((500, 500, 3), dtype=np.uint8)\n",
    "    text = \"Some text in a box!\"\n",
    "\n",
    "    # Get the size of the text box\n",
    "    (text_width, text_height), _ = cv2.getTextSize(text, font, fontScale=font_scale, thickness=1)\n",
    "\n",
    "    # Set the text start position and the box coordinates\n",
    "    text_offset_x = 10\n",
    "    text_offset_y = img.shape[0] - 25\n",
    "    box_coords = ((text_offset_x, text_offset_y), (text_offset_x + text_width + 2, text_offset_y - text_height - 2))\n",
    "\n",
    "    # Draw the text box and text on the image\n",
    "    cv2.rectangle(img, box_coords[0], box_coords[1], rectangle_bgr, cv2.FILLED)\n",
    "    cv2.putText(img, text, (text_offset_x, text_offset_y), font, fontScale=font_scale, color=(0, 0, 0), thickness=1)\n",
    "\n",
    "    # Open the webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "    # Load the face cascade classifier\n",
    "    faceCascade = cv2.CascadeClassifier(path)\n",
    "\n",
    "    # Define emotion labels\n",
    "    emotion_labels = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Neutral\", \"Sad\", \"Surprise\"]\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        faces = faceCascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "        for x, y, w, h in faces:\n",
    "            roi_gray = gray[y:y + h, x:x + w]\n",
    "            roi_color = frame[y:y + h, x:x + w]\n",
    "\n",
    "            final_image = cv2.resize(roi_color, (224, 224))\n",
    "            final_image = np.expand_dims(final_image, axis=0)\n",
    "            final_image = final_image / 255.0\n",
    "\n",
    "            # Predict emotion using the emotion model (replace 'new_model' with your actual model)\n",
    "            Predictions = new_model.predict(final_image)\n",
    "            predicted_emotion = emotion_labels[np.argmax(Predictions)]\n",
    "\n",
    "            # Draw a rectangle around the detected face and display the predicted emotion\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "            cv2.putText(frame, predicted_emotion, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "\n",
    "        # Display the frame with emotions\n",
    "        cv2.imshow('Face Emotion Recognition', frame)\n",
    "\n",
    "        # Break the loop when 'q' is pressed\n",
    "        if cv2.waitKey(2) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
